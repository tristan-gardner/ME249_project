{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.990099\n",
      "1    0.990099\n",
      "2    0.990099\n",
      "3    1.000000\n",
      "4    0.990099\n",
      "5    1.000000\n",
      "6    1.188119\n",
      "7    1.782178\n",
      "Name: x01, dtype: float64 0    0.896552\n",
      "1    1.000000\n",
      "2    1.055172\n",
      "3    0.896552\n",
      "4    1.000000\n",
      "5    1.055172\n",
      "6    0.896552\n",
      "7    1.000000\n",
      "Name: x02, dtype: float64 0    1.009091\n",
      "1    1.000000\n",
      "2    0.993506\n",
      "3    1.009091\n",
      "4    1.000000\n",
      "5    0.993506\n",
      "6    1.009091\n",
      "7    1.000325\n",
      "Name: x03, dtype: float64 0    0.956452\n",
      "1    0.993796\n",
      "2    0.978365\n",
      "3    0.954292\n",
      "4    0.999969\n",
      "5    0.969106\n",
      "6    1.096571\n",
      "7    1.432055\n",
      "Name: y3, dtype: float64\n",
      "[[0.9900990099009901, 0.896551724137931, 1.009090909090909], [0.9900990099009901, 1.0, 1.0], [0.9900990099009901, 1.0551724137931036, 0.9935064935064936], [1.0, 0.896551724137931, 1.009090909090909], [0.9900990099009901, 1.0, 1.0], [1.0, 1.0551724137931036, 0.9935064935064936], [1.188118811881188, 0.896551724137931, 1.009090909090909], [1.7821782178217822, 1.0, 1.0003246753246755]]\n",
      "[[0.99009901 0.89655172 1.00909091]\n",
      " [0.99009901 1.         1.        ]\n",
      " [0.99009901 1.05517241 0.99350649]\n",
      " [1.         0.89655172 1.00909091]\n",
      " [0.99009901 1.         1.        ]\n",
      " [1.         1.05517241 0.99350649]\n",
      " [1.18811881 0.89655172 1.00909091]\n",
      " [1.78217822 1.         1.00032468]]\n"
     ]
    }
   ],
   "source": [
    "'''>>>>> start CodeP2.2F24\n",
    "    V.P. Carey ME249, Fall 2024\n",
    "\n",
    "Intro to Neural Network Modeling \n",
    "Keras model for comparison with first principles model'''\n",
    "\n",
    "#import useful packages\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "#the follwoing 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#raw data in dictionary form x01, x02, x03, y3\n",
    "my_dict = { \n",
    "    'x01' : [20., 20., 20., 20.2, 20., 20.2, 24.0, 36.],\n",
    "    'x02' : [13., 14.5, 15.3, 13., 14.5, 15.3, 13., 14.5],\n",
    "    'x03' : [310.8, 308.0, 306.0, 310.8, 308.0, 306.0, 310.8, 308.1],\n",
    "    'y3' : [30.99, 32.2, 31.7, 30.92, 32.4, 31.4, 35.53, 46.4]\n",
    "}\n",
    "#normalized inputs in array\n",
    "xdata = []\n",
    "xdata = [[20./20.2, 13.0/14.5, 310.8/308.0], [20./20.2, 14.5/14.5, 308.0/308.0]] \n",
    "xdata.append([20./20.2, 15.3/14.5, 306.0/308.0])\n",
    "xdata.append([20.2/20.2, 13.0/14.5, 310.8/308.0]) \n",
    "xdata.append([20./20.2, 14.5/14.5, 308.0/308.0]) \n",
    "xdata.append([20.2/20.2, 15.3/14.5, 306.0/308.0]) \n",
    "xdata.append([24./20.2, 13.0/14.5, 310.8/308.0]) \n",
    "xdata.append([36./20.2, 14.5/14.5, 308.1/308.0]) \n",
    "\n",
    "#data frame\n",
    "df = pd.DataFrame(my_dict)\n",
    "#devide by the median to normalize \n",
    "df.x01= df.x01/20.2\n",
    "df.x02= df.x02/14.5\n",
    "df.x03= df.x03/308.0\n",
    "#normalize output array\n",
    "df.y3= df.y3/32.401\n",
    "df.head\n",
    "print (df.x01, df.x02, df.x03, df.y3)\n",
    "\n",
    "xarray= np.array(xdata)\n",
    "print (xdata)\n",
    "print (xarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_one (Dense)           (None, 1)                 4         \n",
      "                                                                 \n",
      " dense_two (Dense)           (None, 1)                 2         \n",
      "                                                                 \n",
      " dense_three (Dense)         (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8\n",
      "Trainable params: 8\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(3, 1)\n",
      "(1, 1)\n",
      "(1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/3.10test/lib/python3.10/site-packages/keras/initializers/initializers.py:120: UserWarning: The initializer RandomUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "\n",
    "#As seen below, we have created three dense layers each with just one neuron. \n",
    "#A dense layer is a layer in neural network that’s fully connected. \n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 3 in this case. \n",
    "#The activation function we have chosen is ReLU, which stands for rectified linear unit.\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 1.2\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=1.2)\n",
    "\n",
    "# define three layer model with one neuron in each layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, activation=K.elu, input_shape=[3],  kernel_initializer=initializer, name=\"dense_one\"),\n",
    "    keras.layers.Dense(1, activation=K.elu,  kernel_initializer=initializer, name=\"dense_two\"),\n",
    "    keras.layers.Dense(1, activation=K.elu,  kernel_initializer=initializer, name=\"dense_three\")\n",
    "  ])\n",
    "model.summary()\n",
    "\n",
    "#set starting values to those used in first principles model\n",
    "w01n =  1.23 \n",
    "w02n =  0.40 \n",
    "w03n =  0.70\n",
    "b1n =  -0.15\n",
    "w12n =  0.72\n",
    "b2n =  -0.12\n",
    "w23n =  0.7\n",
    "b3n =  0.01\n",
    "\n",
    "weights0 =  [[ w01n], [w02n], [ w03n]]\n",
    "w0array= np.array(weights0)\n",
    "print(np.shape(w0array))\n",
    "bias0 = [b1n]\n",
    "bias0array= np.array(bias0)\n",
    "L0=[]\n",
    "L0.append(w0array)\n",
    "L0.append(bias0array)\n",
    "model.layers[0].set_weights(L0) \n",
    "\n",
    "weights1 =  [[ w12n]]\n",
    "w1array= np.array(weights1)\n",
    "print(np.shape(w1array))\n",
    "bias1 = [b2n]\n",
    "bias1array= np.array(bias1)\n",
    "L1=[]\n",
    "L1.append(w1array)\n",
    "L1.append(bias1array)\n",
    "model.layers[1].set_weights(L1)\n",
    "\n",
    "weights2 =  [[ w23n]]\n",
    "w2array= np.array(weights2)\n",
    "print(np.shape(w2array))\n",
    "bias2 = [b3n]\n",
    "bias2array= np.array(bias2)\n",
    "L2=[]\n",
    "L2.append(w2array)\n",
    "L2.append(bias2array)\n",
    "model.layers[2].set_weights(L2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’re using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#It’s one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer that’s reliable and fast.\n",
    "#We’re compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean absolute error. After the compilation of the model, we’ll use the fit method with 100 epochs.\n",
    "\n",
    "#Running model.fit successive times extends the calculation to addtional epochs.\n",
    "\n",
    "rms = keras.optimizers.RMSprop(0.0035)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms,metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "Epoch 1/400\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0200 - mae: 0.0200\n",
      "Epoch 2/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0175 - mae: 0.0175\n",
      "Epoch 3/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0143 - mae: 0.0143\n",
      "Epoch 4/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0150\n",
      "Epoch 5/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 6/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0140\n",
      "Epoch 7/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161\n",
      "Epoch 8/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0172\n",
      "Epoch 9/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0137\n",
      "Epoch 10/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0174 - mae: 0.0174\n",
      "Epoch 11/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0211 - mae: 0.0211\n",
      "Epoch 12/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163\n",
      "Epoch 13/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0166 - mae: 0.0166\n",
      "Epoch 14/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0133 - mae: 0.0133\n",
      "Epoch 15/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.0176\n",
      "Epoch 16/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0193 - mae: 0.0193\n",
      "Epoch 17/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 18/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0187 - mae: 0.0187\n",
      "Epoch 19/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 20/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0151\n",
      "Epoch 21/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0139\n",
      "Epoch 22/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 23/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0147\n",
      "Epoch 24/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0150\n",
      "Epoch 25/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 26/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0143\n",
      "Epoch 27/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161\n",
      "Epoch 28/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0178\n",
      "Epoch 29/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0139 - mae: 0.0139\n",
      "Epoch 30/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 0.0175\n",
      "Epoch 31/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0226 - mae: 0.0226\n",
      "Epoch 32/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0161\n",
      "Epoch 33/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169\n",
      "Epoch 34/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0135\n",
      "Epoch 35/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0173 - mae: 0.0173\n",
      "Epoch 36/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0204 - mae: 0.0204\n",
      "Epoch 37/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0164\n",
      "Epoch 38/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164\n",
      "Epoch 39/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 40/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177\n",
      "Epoch 41/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 42/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 43/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 44/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 45/400\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 46/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 47/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 48/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 49/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0193 - mae: 0.0193\n",
      "Epoch 50/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 51/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 52/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0184 - mae: 0.0184\n",
      "Epoch 53/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 54/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0172 - mae: 0.0172\n",
      "Epoch 55/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184\n",
      "Epoch 56/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0153\n",
      "Epoch 57/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 58/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 59/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0150\n",
      "Epoch 60/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0142 - mae: 0.0142\n",
      "Epoch 61/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 62/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0146\n",
      "Epoch 63/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0153\n",
      "Epoch 64/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 65/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0142\n",
      "Epoch 66/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0165 - mae: 0.0165\n",
      "Epoch 67/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0177 - mae: 0.0177\n",
      "Epoch 68/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0137\n",
      "Epoch 69/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 70/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0224 - mae: 0.0224\n",
      "Epoch 71/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164\n",
      "Epoch 72/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0168\n",
      "Epoch 73/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0133\n",
      "Epoch 74/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0177 - mae: 0.0177\n",
      "Epoch 75/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0200 - mae: 0.0200\n",
      "Epoch 76/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0167\n",
      "Epoch 77/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162\n",
      "Epoch 78/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 79/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 80/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0187 - mae: 0.0187\n",
      "Epoch 81/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 82/400\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 83/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0184 - mae: 0.0184\n",
      "Epoch 84/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 85/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 86/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 87/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 88/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 89/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 90/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 91/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 92/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 93/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 94/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 95/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 96/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 97/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 98/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 99/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 100/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 101/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 102/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 103/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 104/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 105/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 106/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 107/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 0.0193\n",
      "Epoch 108/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 109/400\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 110/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 111/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 112/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0200 - mae: 0.0200\n",
      "Epoch 113/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 114/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0148 - mae: 0.0148\n",
      "Epoch 115/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0146\n",
      "Epoch 116/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 117/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0144 - mae: 0.0144\n",
      "Epoch 118/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0157 - mae: 0.0157\n",
      "Epoch 119/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0178 - mae: 0.0178\n",
      "Epoch 120/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0140 - mae: 0.0140\n",
      "Epoch 121/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 0.0169\n",
      "Epoch 122/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 0.0175\n",
      "Epoch 123/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0135 - mae: 0.0135\n",
      "Epoch 124/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 125/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0218 - mae: 0.0218\n",
      "Epoch 126/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168\n",
      "Epoch 127/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0166\n",
      "Epoch 128/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0132 - mae: 0.0132\n",
      "Epoch 129/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 130/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.0194\n",
      "Epoch 131/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0171 - mae: 0.0171\n",
      "Epoch 132/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 0.0184\n",
      "Epoch 133/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0153 - mae: 0.0153\n",
      "Epoch 134/400\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 135/400\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 136/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0150 - mae: 0.0150\n",
      "Epoch 137/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0141 - mae: 0.0141\n",
      "Epoch 138/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 139/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0146 - mae: 0.0146\n",
      "Epoch 140/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0153 - mae: 0.0153\n",
      "Epoch 141/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 142/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0142 - mae: 0.0142\n",
      "Epoch 143/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0164\n",
      "Epoch 144/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0177 - mae: 0.0177\n",
      "Epoch 145/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0137\n",
      "Epoch 146/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0178 - mae: 0.0178\n",
      "Epoch 147/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0225 - mae: 0.0225\n",
      "Epoch 148/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0163\n",
      "Epoch 149/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168\n",
      "Epoch 150/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0133\n",
      "Epoch 151/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0176 - mae: 0.0176\n",
      "Epoch 152/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 0.0201\n",
      "Epoch 153/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166\n",
      "Epoch 154/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0162 - mae: 0.0162\n",
      "Epoch 155/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 156/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 157/400\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0187 - mae: 0.0187\n",
      "Epoch 158/400\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 159/400\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 160/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 161/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 162/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 163/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 164/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0185\n",
      "Epoch 165/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 166/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0127\n",
      "Epoch 167/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 168/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 169/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 170/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 171/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 172/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 173/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 174/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 175/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 176/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0189\n",
      "Epoch 177/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 178/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 179/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 180/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 181/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 0.0191\n",
      "Epoch 182/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 183/400\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 184/400\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0192 - mae: 0.0192\n",
      "Epoch 185/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 186/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 187/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161\n",
      "Epoch 188/400\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 189/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 190/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0205 - mae: 0.0205\n",
      "Epoch 191/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0184\n",
      "Epoch 192/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 193/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0152 - mae: 0.0152\n",
      "Epoch 194/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0136\n",
      "Epoch 195/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 0.0184\n",
      "Epoch 196/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0149 - mae: 0.0149\n",
      "Epoch 197/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0147 - mae: 0.0147\n",
      "Epoch 198/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 199/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0145 - mae: 0.0145\n",
      "Epoch 200/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0159\n",
      "Epoch 201/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 202/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0140\n",
      "Epoch 203/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0170 - mae: 0.0170\n",
      "Epoch 204/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0232 - mae: 0.0232\n",
      "Epoch 205/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0158 - mae: 0.0158\n",
      "Epoch 206/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0171 - mae: 0.0171\n",
      "Epoch 207/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0136\n",
      "Epoch 208/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0169 - mae: 0.0169\n",
      "Epoch 209/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0169\n",
      "Epoch 210/400\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0132 - mae: 0.0132\n",
      "Epoch 211/400\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0185 - mae: 0.0185\n",
      "Epoch 212/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0203 - mae: 0.0203\n",
      "Epoch 213/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0170 - mae: 0.0170\n",
      "Epoch 214/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0162\n",
      "Epoch 215/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 216/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 217/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 218/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 219/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 220/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 221/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0187 - mae: 0.0187\n",
      "Epoch 222/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 223/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0129 - mae: 0.0129\n",
      "Epoch 224/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0190 - mae: 0.0190\n",
      "Epoch 225/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 0.0188\n",
      "Epoch 226/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0126\n",
      "Epoch 227/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0160 - mae: 0.0160\n",
      "Epoch 228/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0125\n",
      "Epoch 229/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0130\n",
      "Epoch 230/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0196 - mae: 0.0196\n",
      "Epoch 231/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0197 - mae: 0.0197\n",
      "Epoch 232/400\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 233/400\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0184 - mae: 0.0184\n",
      "Epoch 234/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0152 - mae: 0.0152\n",
      "Epoch 235/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135\n",
      "Epoch 236/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 237/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0148\n",
      "Epoch 238/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0146 - mae: 0.0146\n",
      "Epoch 239/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0181\n",
      "Epoch 240/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0144 - mae: 0.0144\n",
      "Epoch 241/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0158 - mae: 0.0158\n",
      "Epoch 242/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0179\n",
      "Epoch 243/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0140 - mae: 0.0140\n",
      "Epoch 244/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 0.0169\n",
      "Epoch 245/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 0.0175\n",
      "Epoch 246/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0135\n",
      "Epoch 247/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 248/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0220 - mae: 0.0220\n",
      "Epoch 249/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0168 - mae: 0.0168\n",
      "Epoch 250/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0166\n",
      "Epoch 251/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0131 - mae: 0.0131\n",
      "Epoch 252/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0183 - mae: 0.0183\n",
      "Epoch 253/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0195 - mae: 0.0195\n",
      "Epoch 254/400\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0171 - mae: 0.0171\n",
      "Epoch 255/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0160 - mae: 0.0160\n",
      "Epoch 256/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0128\n",
      "Epoch 257/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 0.0186\n",
      "Epoch 258/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0184 - mae: 0.0184\n",
      "Epoch 259/400\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0151 - mae: 0.0151\n",
      "Epoch 260/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0138\n",
      "Epoch 261/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0182\n",
      "Epoch 262/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0147 - mae: 0.0147\n",
      "Epoch 263/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0149 - mae: 0.0149\n",
      "Epoch 264/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0180\n",
      "Epoch 265/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0143 - mae: 0.0143\n",
      "Epoch 266/400\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0161 - mae: 0.0161\n",
      "Epoch 267/400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0178 - mae: 0.0178\n",
      "Epoch 268/400\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0139 - mae: 0.0139Restoring model weights from the end of the best epoch: 188.\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0139 - mae: 0.0139\n",
      "Epoch 268: early stopping\n",
      "best epoch =  188\n",
      "mae =  0.013854660093784332\n",
      "smallest loss = 0.012461163103580475\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, we’ll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured I’d give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 80, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = tf.keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)\n",
    "\n",
    "historyData = model.fit(xarray,df.y3,epochs=400,callbacks=[es]) # epochs 800 -> 400\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "mae = historyData.history['mae']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('mae = ', mae[-1])\n",
    "print('smallest loss =', np.min(loss_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w01 =  1.2134895 w02 =  0.35242113 w03 =  0.7117379\n",
      "b1 =  -0.14435415\n",
      "w12 =  0.70460844\n",
      "b2 =  -0.10825239\n",
      "w23 =  0.6795096\n",
      "b3 =  0.028053714\n",
      "x01/20.2,  x02/14.5,   x03/308.0,  y3/32.4,  a3:\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "0.9900990099009901 0.896551724137931 1.009090909090909 0.9564519613592172 [[0.95578134]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "0.9900990099009901 1.0 1.0 0.9937964877627233 [[0.9701388]]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "0.9900990099009901 1.0551724137931036 0.9935064935064936 0.9783648652819357 [[0.97723556]]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1.0 0.896551724137931 1.009090909090909 0.954291534211907 [[0.96153396]]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "0.9900990099009901 1.0 1.0 0.9999691367550383 [[0.9701388]]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1.0 1.0551724137931036 0.9935064935064936 0.9691058917934631 [[0.98298794]]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1.188118811881188 0.896551724137931 1.009090909090909 1.096571093484769 [[1.0708318]]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1.7821782178217822 1.0 1.0003246753246755 1.4320545662170918 [[1.4304512]]\n",
      "  \n",
      "x01,  x02,   x03,  y3,  a3*32.4:\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "20.0 13.0 310.8 30.989043548038634 [[30.967318]]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "20.0 14.5 308.0 32.19900620351223 [[31.432499]]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "20.0 15.3 306.0 31.699021635134713 [[31.662434]]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "20.2 13.0 310.8 30.919045708465788 [[31.153702]]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "20.0 14.5 308.0 32.39900003086324 [[31.432499]]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "20.2 15.3 306.0 31.3990308941082 [[31.84881]]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "23.999999999999996 13.0 310.8 35.52890342890652 [[34.69495]]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "36.0 14.5 308.1000000000001 46.398567945433776 [[46.34662]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#For results of training network:\n",
    "\n",
    "#keras.layer.get_weights() function retrieves weight values\n",
    "first_layer_weights = model.layers[0].get_weights()[0]\n",
    "w01 = first_layer_weights[0][0]\n",
    "w02 = first_layer_weights[1][0]\n",
    "w03 = first_layer_weights[2][0]\n",
    "first_layer_bias  = model.layers[0].get_weights()[1]\n",
    "b1 = first_layer_bias\n",
    "second_layer_weights = model.layers[1].get_weights()[0]\n",
    "w12 = second_layer_weights[0][0]\n",
    "second_layer_bias  = model.layers[1].get_weights()[1]\n",
    "b2 = second_layer_bias\n",
    "third_layer_weights = model.layers[2].get_weights()[0]\n",
    "w23 = third_layer_weights[0][0]\n",
    "third_layer_bias  = model.layers[2].get_weights()[1]\n",
    "b3 = third_layer_bias\n",
    "\n",
    "#print weights and biases\n",
    "# print (first_layer_weights)\n",
    "print ('w01 = ', w01, 'w02 = ', w02, 'w03 = ', w03)\n",
    "# print (first_layer_bias)\n",
    "print ('b1 = ', b1[0])\n",
    "# print (second_layer_weights)\n",
    "print ('w12 = ', w12)\n",
    "# print (second_layer_bias)\n",
    "print ('b2 = ', b2[0])\n",
    "# print (third_layer_weights)\n",
    "print ('w23 = ', w23)\n",
    "# print (third_layer_bias)\n",
    "print ('b3 = ', b3[0])\n",
    "\n",
    "#use model.predict() function to print model predictions for data conditions\n",
    "xarray= np.array(xdata)\n",
    "print ('x01/20.2,  x02/14.5,   x03/308.0,  y3/32.4,  a3:')\n",
    "test = []\n",
    "for i in range(0,8): \n",
    "    test = [[xarray[i][0], xarray[i][1], xarray[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    print (xarray[i][0], xarray[i][1], xarray[i][2], df.y3[i], a3)\n",
    "print('  ')\n",
    "print ('x01,  x02,   x03,  y3,  a3*32.4:')\n",
    "for i in range(0,8): \n",
    "    test = [[xarray[i][0], xarray[i][1], xarray[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    print (xarray[i][0]*20.2, xarray[i][1]*14.5, xarray[i][2]*308.0, df.y3[i]*32.4, a3*32.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
